<!DOCTYPE html>
<html lang="en">
<head>
    <title>
        UCLA NLP Seminar Series
    </title>
    <!-- Next line is for the nice mobile view -->
    <link rel="apple-touch-icon" sizes="180x180" href="https://uclanlp.github.io/nlp-seminar/icons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://uclanlp.github.io/nlp-seminar/icons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://uclanlp.github.io/nlp-seminar/icons/favicon-16x16.png">
    <link rel="icon" type="image/x-icon" href="https://uclanlp.github.io/nlp-seminar/icons/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="https://uclanlp.github.io/nlp-seminar/style.css">
</head>
<script src="https://uclanlp.github.io/nlp-seminar/script.js"></script>


<body>

    <header>
        <div class="header-content">
            <div class="lab-logos">
                <img src="https://web.cs.ucla.edu/~kwchang/img/uclanlp.png" alt="Kai-Wei Chang's Lab">
            </div>
            <div class="header-text">
                <h1>UCLA NLP Seminar Series</h1>
                <p>Welcome to our weekly seminar series.</p>
            </div>
            <div class="lab-logos">
                <img src="https://web.cs.ucla.edu/~kwchang/img/uclanlp.png" alt="Kai-Wei Chang's Lab">
            </div>
        </div>
    </header>


    <nav class="nav-container">
              <div class="nav-menu">
            <ul class="menu-list">
                <li class="menu-item"><a href="https://uclanlp.github.io/nlp-seminar/">Home</a></li>
                <li class="menu-item"><a href="past_talks.html">Past Talks</a></li>
            </ul>
        </div>
    </nav>

    <main>

        <table class="seminar-schedule">
            <thead>
                <tr>
                    <th>Date   </th>
                    <th>Speaker</th>
                    <th>Title</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                  <td>January 9</td>
                    <td><a href="https://liweijiang.github.io/">Liwei Jiang</a></td>
                    <td>Humanistic, Pluralistic, and Coevolutionary AI Safety and Alignment</td>
                </tr>
                <tr>
                  <td>January 23</td>
                    <td><a href="https://stanford.edu/~cgpotts/">Christopher Potts</a></td>
                    <td>The Archai of Palimpsestic Memorization</td>
                </tr>
                <tr>
                  <td>January 30</td>
                    <td><a href="https://swabhs.com">Swabha Swayamdipta</a></td>
                    <td>TBD</td>
                </tr> 
                <tr>
                  <td>February 6</td>
                    <td><a href="https://shrimai.github.io">Shrimai Prabhumoye</a></td>
                    <td>TBD</td>
                </tr>              
                
            </tbody>
        </table>



<h2>&#128640; Upcoming Talks </h2>

<!-- Chris block -->
<div class="talk"  onclick="toggleDetails(this)">
        <div class="talk-summary">
            <div class="date">
                <div class="month">JAN</div>
                <div class="day">23</div>
            </div>
            <div class="speaker-image">
                <a href="https://stanford.edu/~cgpotts/" target="_block">
                <img src="https://drive.google.com/thumbnail?id=1d3cy8hdHSAM3HA_wVHXyOlv5cYijYt-4&sz=w1000" alt="Christopher Potts" style="max-height: 300px;"/>
                </a>
            </div>
            <div class="speaker-text">
                <h3>The Archai of Palimpsestic Memorization</h3>
                <p><img src="icons/person.png" alt="Person Icon" class="icon"><a href="The Archai of Palimpsestic Memorization">Christopher Potts</a></p>
                <p><img src="icons/clock.png" alt="Clock Icon" class="icon">January 23, 2026, 2:00 PM PT</p>
                <p><img src="icons/zoom.png" alt="Zoom Icon" class="icon"><a href="#">https://ucla.zoom.us/meeting/register/axur3N-pSSSHB5Oyc155Kw</a></p>
                </div>
            <div class="footer">
                <button class="more-details">More Details</button>
              </div>
        </div>
        <div class="talk-details">
            <p><strong>Speaker Bio:</strong>Christopher Potts is Professor of Linguistics and, by courtesy, of Computer Science at Stanford, and a faculty member in the Stanford NLP Group and the Stanford AI Lab. His research group uses computational methods to explore topics in context-dependent language use, systematicity and compositionality, model interpretability, information retrieval, and foundation model programming. This research combines methods from linguistics, cognitive psychology, and computer science, in the service of both scientific discovery and technology development.</p>
            <p><strong>Abstract:</strong>Kuditipudi, Huang, Zhu et al. (2025, "Blackbox model provenance via palimpsestic membership inference") provide an extremely effective, lightweight family of tests for whether one language model M1 is a derivative of another language model M2. The basic form of the test works like this: measure the correlation between the training data ordering for M1 and the likelihood that M2 assigns to those training examples. Fascinating … but how on earth did the authors come up with this? The tests were primarily developed by the three lead authors (Rohith, Jing, and Sally; henceforth RJS), and we may never know precisely what mix of genius, cosmic inspiration, and deep scholarship was at work here. However, I think we can see, at least in retrospect, that the necessary ingredients for proposing this test were basically present in the existing literature already. This talk will review that evidence, taking us on a hypothetical journey to these model provenance tests. I'll close by reviewing what we know the tests can teach us, and speculating about potential new applications and extensions of these ideas.</p>
        </div>
    </div>

<h2> Past Talks </h2>
<!-- Liwei block -->
<div class="talk"  onclick="toggleDetails(this)">
        <div class="talk-summary">
            <div class="date">
                <div class="month">JAN</div>
                <div class="day">9</div>
            </div>
            <div class="speaker-image">
                <a href="https://liweijiang.github.io/" target="_block">
                <img src="https://liweijiang.github.io/static/avatar.png" alt="Liwei Jiang" style="max-height: 300px;"/>
                </a>
            </div>
            <div class="speaker-text">
                <h3>Humanistic, Pluralistic, and Coevolutionary AI Safety and Alignment</h3>
                <p><img src="icons/person.png" alt="Person Icon" class="icon"><a href="https://liweijiang.github.io/">Liwei Jiang</a></p>
                <p><img src="icons/clock.png" alt="Clock Icon" class="icon">January 9, 2026, 2:00 PM PT</p>
                <p><img src="icons/zoom.png" alt="Zoom Icon" class="icon"><a href="#">https://ucla.zoom.us/meeting/register/h1yPiSJmTdKdXDq5BE9pXA</a></p>
                </div>
            <div class="footer">
                <button class="more-details">More Details</button>
              </div>
        </div>
        <div class="talk-details">
            <p><strong>Speaker Bio:</strong>Liwei Jiang is a final-year PhD candidate in the Paul G. Allen School of Computer Science and Engineering at the University of Washington, where her research centers on humanistic, pluralistic, and coevolutionary AI safety and alignment. She develops computational frameworks for modeling human morality, advances culturally grounded and pluralistic value alignment, designs holistic safeguards for large language models, and explores future-oriented coevolutionary paradigms that integrate human-AI and AI-AI learning dynamics. Her work appears in top venues across AI, ML, and NLP, earning multiple Oral, Spotlight, Outstanding Paper, and Best Paper distinctions. She received her BA in Computer Science and Mathematics from Colby College, graduating summa cum laude.</p>
            <p><strong>Abstract:</strong>"In this talk, I will explore a central challenge for the next generation of AI systems: how to ensure that AI aligns with human morality, values, and needs in a world where those values are complex, diverse, and constantly evolving. As AI becomes deeply embedded in social, creative, and safety-critical settings, alignment must move beyond high-level principles toward concrete scientific frameworks and deployable technical methods. My work develops such a foundation and advances alignment across three complementary directions. I will begin by discussing how we can model human morality and pluralistic values in ways that are computationally grounded yet deeply informed by philosophy and cognitive science. This includes building representations of commonsense morality, cultural variation, and individual preferences, and showing how these learned structures can guide decision-making in large language models. Next, I will describe a line of research focused on putting value alignment into practice by developing holistic safety frameworks for language models. These include integrated red-teaming and defense pipelines, multilingual moderation tools, and system-level mechanisms that make LLMs steerable, controllable, and robust to evolving risks in real-world environments. Finally, I will turn to a forward-looking perspective on alignment: the idea of human–AI coevolution. I will outline how AI can augment human capabilities, how AI-to-AI interaction can drive iterative self-improvement, and how humans and AI together can form synergistic feedback loops that enable more capable, adaptive, and beneficial systems. Across these threads, the talk presents a unified vision of humanistic, pluralistic, and coevolutionary AI alignment—one that integrates moral reasoning, technical safety, and human–AI collaboration to support a future where AI systems act in ways that are meaningfully aligned with human values and ultimately contribute to human flourishing."</p>
        </div>
    </div>



        
<h2>Organizing Committee</h2>
    <div class="committee-content">
        <h3>Faculty</h3>
        <div class="row">
                <div class="speaker-image">
                        <a href="https://web.cs.ucla.edu/~kwchang/" target="_block">
                            <img src="https://web.cs.ucla.edu/~kwchang/img/myphoto.jpg" style="max-height: 200px; max-width: 200px;"/>
                        </a>
                    </figure>
                    <p><b>Prof. Kai-Wei Chang</b></p>
                </div>

                <div class="speaker-image">
                    <a href="https://violetpeng.github.io/" target="_block">
                        <img src="https://violetpeng.github.io/photos/profile22.png" style="max-height: 200px; max-width: 200px;"/>
                    </a>
                </figure>
                <p><b>Prof. Nanyun Peng </b></p>
                </div>

                <div class="speaker-image">
                    <a href="https://saadiagabriel.com/" target="_block">
                        <img src="https://saadiagabriel.com/website.png" style="max-height: 200px; max-width: 200px;"/>
                    </a>
                </figure>
                <p><b>Prof. Saadia Gabriel </b></p>
                </div>

                <div class="speaker-image">
                    <a href="https://www.coalas-lab.com/elisakreiss" target="_block">
                        <img src="https://comm.ucla.edu/wp-content/uploads/2023/08/ElisaSept2022.png" style="max-height: 200px; max-width: 200px;"/>
                    </a>
                </figure>
                <p><b>Prof. Elisa Kreiss </b></p>
            </div>

            </div>

    
        <div style="clear: both; text-align: left;">
            <h3>Students</h3>
            </div>
        <div class="row">
                <div class="speaker-image">
                        <a href="https://tanmayparekh.github.io/" target="_block">
                            <img src="https://tanmayparekh.github.io/vertical-ucla-pic.jpeg" style="max-height: 200px; max-width: 200px;"/>
                        </a>
                    </figure>
                    <p><b>Tanmay Parekh</b></p>
                </div>

                <div class="speaker-image">
                    <a href="https://mohsenfayyaz.github.io/" target="_block">
                        <img src="https://mohsenfayyaz.github.io/images/profile.jpg" style="max-height: 200px; max-width: 200px;"/>
                    </a>
                </figure>
                <p><b>Mohsen Fayyaz</b></p>
            </div>

                <div class="speaker-image">
                    <a href="https://asuvarna31.github.io" target="_block">
                        <img src="https://asuvarna31.github.io/images/IMG_0888.jpg" style="max-height: 200px; max-width: 200px;"/>
                    </a>
                </figure>
                <p><b>Ashima Suvarna</b></p>
                </div>
                </div>
                

                <div class="speaker-image">
                    <a href="https://yingjia.one/" target="_block">
                        <img src="https://scholar.googleusercontent.com/citations?view_op=medium_photo&user=yCZT5ykAAAAJ&citpid=1" style="max-height: 200px;"/>
                    </a>
                </figure>
                <p><b>Yingjia Wan</b></p>
                </div>

                        <div class="row">

                   <div class="speaker-image">
                    <a href="https://salmanrahman.net/" target="_block">
                        <img src="https://salmanrahman.net/assets/salman-img.jpg" style="max-height: 200px;"/>
                    </a>
                </figure>
                <p><b>Salman Rahman </b></p>
                </div>

                <div class="speaker-image">
                    <a href="https://www.lucasbandarkar.com/" target="_block">
                        <img src="https://scholar.googleusercontent.com/citations?view_op=medium_photo&user=-ki975oAAAAJ&citpid=3" style="max-height: 200px; max-width: 200px;"/>
                    </a>
                </figure>
                <p><b>Lucas Bandarkar</b></p>
                </div>

            </div>


    </div>

    </main>

</body>

</html>
