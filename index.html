<!DOCTYPE html>
<html lang="en">
<head>
    <title>
        UCLA NLP Seminar Series
    </title>
    <!-- Next line is for the nice mobile view -->
    <link rel="apple-touch-icon" sizes="180x180" href="https://uclanlp.github.io/nlp-seminar/icons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://uclanlp.github.io/nlp-seminar/icons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://uclanlp.github.io/nlp-seminar/icons/favicon-16x16.png">
    <link rel="icon" type="image/x-icon" href="https://uclanlp.github.io/nlp-seminar/icons/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="https://uclanlp.github.io/nlp-seminar/style.css">
</head>
<script src="https://uclanlp.github.io/nlp-seminar/script.js"></script>


<body>

    <header>
        <div class="header-content">
            <div class="lab-logos">
                <img src="https://web.cs.ucla.edu/~kwchang/img/uclanlp.png" alt="Kai-Wei Chang's Lab">
            </div>
            <div class="header-text">
                <h1>UCLA NLP Seminar Series</h1>
                <p>Welcome to our weekly seminar series.</p>
            </div>
            <div class="lab-logos">
                <img src="https://web.cs.ucla.edu/~kwchang/img/uclanlp.png" alt="Kai-Wei Chang's Lab">
            </div>
        </div>
    </header>


    <nav class="nav-container">
              <div class="nav-menu">
            <ul class="menu-list">
                <li class="menu-item"><a href="https://uclanlp.github.io/nlp-seminar/">Home</a></li>
                <li class="menu-item"><a href="past_talks.html">Past Talks</a></li>
            </ul>
        </div>
    </nav>

    <main>
<!--         <h2>We have a great lineup of speakers for Spring 2025! Please check back in a few weeks. </h2> -->
        <table class="seminar-schedule">
            <thead>
                <tr>
                    <th>Date   </th>
                    <th>Speaker</th>
                    <th>Title</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                  <td>October 3</td>
                    <td><a href="https://brihijoshi.github.io/">Brihi Joshi</a></td>
                    <td>Towards Richer User Signals for Personalization</td>
                </tr>
                <tr>
                  <td>October 10</td>
                    <td><a href="https://www.mit.edu/~jda/">Jacob Andreas</a></td>
                    <td>Just Asking Questions</td>
                </tr>
                <tr>
                  <td>October 17</td>
                    <td><a href="https://aviralkumar2907.github.io/">Aviral Kumar</a></td>
                    <td>The Importance of Exploration for Test-Time Scaling</td>
                </tr> 
                <tr>
                  <td>October 24</td>
                    <td><a href="mailto:pkordjamshidi@cmu.edu">Parisa Kordjamshidi</a></td>
                    <td>Reasoning under Uncertainty with Large Multimodal Language Models</td>
                </tr>
                <tr>
                  <td>October 31</td>
                    <td><a href="https://roseyu.com/">Rose Yu</a></td>
                    <td>TBD</td>
                </tr>
                <tr>
                  <td>November 14</td>
                    <td><a href="https://armancohan.com/">Arman Cohan</a></td>
                    <td>TBD</td>
                </tr>
                <tr>
                  <td>November 21</td>
                    <td><a href="https://sherryy.github.io/">Sherry Yang</a></td>
                    <td>TBD</td>
                </tr>
                
                
            </tbody>
        </table>



<h2>&#128640; Upcoming Talks </h2>
<!-- Aviral block -->
    <div class="talk"  onclick="toggleDetails(this)">
        <div class="talk-summary">
            <div class="date">
                <div class="month">OCT</div>
                <div class="day">17</div>
            </div>
            <div class="speaker-image">
                <a href="https://aviralkumar2907.github.io/" target="_block">
                <img src="https://aviralkumar2907.github.io/website_final.JPG" alt="Aviral Kumar" style="max-height: 300px;"/>
                </a>
            </div>
            <div class="speaker-text">
                <h3>The Importance of Exploration for Test-Time Scaling</h3>
                <p><img src="icons/person.png" alt="Person Icon" class="icon"><a href="https://aviralkumar2907.github.io/">Aviral Kumar</a></p>
                <p><img src="icons/clock.png" alt="Clock Icon" class="icon">October 17, 2025, 2:00 PM</p>
                <!-- <p><img src="icons/location.png" alt="Location Icon" class="icon">TBD</p> -->
                <p><img src="icons/zoom.png" alt="Zoom Icon" class="icon">https://ucla.zoom.us/meeting/register/1LfTUChHRWOA1zApfUcAlA</p>
            </div>
            <div class="footer">
                <button class="more-details">More Details</button>
              </div>
        </div>
        <div class="talk-details">
            <p><strong>Speaker Bio:</strong> Aviral Kumar is an Assistant Professor of Computer Science and Machine Learning at Carnegie Mellon University, where he started in September 2024. He finished his PhD from UC Berkeley in 2023. His research focuses on reinforcement learning (RL), spanning fundamental advances in offline RL and scaling up RL, and more recently, the use of RL to train large language models (LLMs) and optimize test-time compute. He is a recipient of the Samsung AI Researcher of the Year Award (2024), the Schmidt Sciences AI2050 Early Career Fellowship (2024), and multiple best paper awards across workshops in RL, LLMs, and robotics at ICLR and ICML. </p>
            <p><strong>Abstract:</strong> RL has enabled language models to optimize long chains of thought (CoTs), yet the field still lacks clarity on what makes these approaches succeed. Conflicting empirical results across papers often stem from differences in setting rather than principle. In this talk, I will share our perspective: effective test-time scaling hinges on in-context exploration, the ability of a model to internally experiment and infer generalizable algorithmic procedures using additional compute at inference. I will describe two RL-based approaches for training models to perform such exploration. First, I will present e3, a curriculum-based recipe that teaches models to chain together existing skills in the base model, yielding the state-of-the-art <2B language model for math reasoning. Second, I will discuss cases where chaining alone is insufficient. There, we guide exploration by conditioning the model’s CoT on concise, self-generated natural language abstractions: short procedural summaries produced before launching into long reasoning traces. These abstractions help steer test-time search more effectively. Across tasks, conditioning RL on abstractions significantly improves in-context exploration and yields sustained performance gains even when conventional pass@k scaling plateaus.I will also talk briefly about some ongoing work that builds on these ideas to improve exploration for test-time scaling.</p>
        </div>
    </div>
<!-- Parisa block -->
    <div class="talk"  onclick="toggleDetails(this)">
        <div class="talk-summary">
            <div class="date">
                <div class="month">OCT</div>
                <div class="day">24</div>
            </div>
            <div class="speaker-image">
                <a href="https://www.cse.msu.edu/~kordjams/" target="_block">
                <img src="https://www.cse.msu.edu/~kordjams/DSC_2012_2.png" alt="Parisa Kordjamshidi" style="max-height: 300px;"/>
                </a>
            </div>
            <div class="speaker-text">
                <h3>Reasoning under Uncertainty with Large Multimodal Language Models</h3>
                <p><img src="icons/person.png" alt="Person Icon" class="icon"><a href="https://www.cse.msu.edu/~kordjams/">Parisa Kordjamshidi</a></p>
                <p><img src="icons/clock.png" alt="Clock Icon" class="icon">October 24, 2025, 2:00 PM</p>
                <p><img src="icons/location.png" alt="Location Icon" class="icon">289, Engineering VI</p>
                </div>
            <div class="footer">
                <button class="more-details">More Details</button>
              </div>
        </div>
        <div class="talk-details">
            <p><strong>Speaker Bio:</strong> Parisa Kordjamshidi is an Associate Professor of Computer Science and Engineering at Michigan State University. Her research focuses on Natural Language Processing, multimodal reasoning across vision and language, and neuro-symbolic learning. She received her Ph.D. from KU Leuven and conducted postdoctoral research at the University of Illinois Urbana-Champaign. She is a recipient of the NSF CAREER, Amazon Faculty Research, and Fulbright Scholar Awards, and her research team received the NAACL 2025 Outstanding Research Paper Award. Dr. Kordjamshidi serves as Associate Editor of JAIR, Co-editor in chief of ARR (2026), Action Editor for TACL and has held roles in organization committee of major conferences including ACL, NAACL, EACL, EMNLP, ECML-PKDD, and AAAI. Currently, she is a visiting Associate Professor at UCLA spending a part of her sabbatical. </p>
            <p><strong>Abstract:</strong> Uncertainty in intelligent models has multiple facets. One aspect concerns a model’s own uncertainty or confidence in its generated outputs. Another pertains to factual knowledge about uncertainty within specific concepts. For example, statements such as “10–20% of lifelong smokers will develop lung cancer” express factual uncertainty derived from statistical data analyses and represented in text. A key research question is whether language models can form and convey such factual uncertainties—integrating information, drawing on their internal knowledge, and aligning this with their confidence when expressing opinions. While addressing this question is highly challenging, I will present our research that explores related directions and the following research question: 1) How do language models understand uncertainty expressions in natural language and perform probabilistic inference over them? 2) How can models be trained to follow the principles of probabilistic reasoning when handling uncertainty in text? 3) How can today’s large models reason over uncertain text? specifically focusing on mapping language into formal probabilistic logic programs?, and finally, in the context of grounding natural language in the visual modality, 4) How can uncertainty in perception be explicitly represented in reasoning? specifically focusing on mappings to differentiable probabilistic programs.</p>
        </div>
    </div>
<h2>Past Talks </h2>
<!-- Jacob block -->
    <div class="talk"  onclick="toggleDetails(this)">
        <div class="talk-summary">
            <div class="date">
                <div class="month">OCT</div>
                <div class="day">10</div>
            </div>
            <div class="speaker-image">
                <a href="https://www.mit.edu/~jda/" target="_block">
                <img src="https://www.mit.edu/~jda/figs/head_small.jpg" alt="Jacob Andreas" style="max-height: 300px;"/>
                </a>
            </div>
            <div class="speaker-text">
                <h3>Just Asking Questions</h3>
                <p><img src="icons/person.png" alt="Person Icon" class="icon"><a href="https://www.mit.edu/~jda/">Jacob Andreas</a></p>
                <p><img src="icons/clock.png" alt="Clock Icon" class="icon">October 10, 2025, 2:00 PM</p>
                <!-- <p><img src="icons/location.png" alt="Location Icon" class="icon">289, Engineering VI</p> -->
                <p><img src="icons/zoom.png" alt="Zoom Icon" class="icon">https://ucla.zoom.us/meeting/register/1LfTUChHRWOA1zApfUcAlA</p>
            </div>
            <div class="footer">
                <button class="more-details">More Details</button>
              </div>
        </div>
        <div class="talk-details">
            <p><strong>Speaker Bio:</strong>Jacob Andreas is an associate professor at MIT in the Department of Electrical Engineering and Computer Science as well as the Computer Science and Artificial Intelligence Laboratory. His research aims to understand the computational foundations of language learning, and to build intelligent systems that can learn from human guidance. Jacob earned his Ph.D. from UC Berkeley, his M.Phil. from Cambridge (where he studied as a Churchill scholar) and his B.S. from Columbia. He has received a Sloan fellowship, an NSF CAREER award, MIT's Junior Bose and Kolokotrones teaching awards, and paper awards at ACL, ICML and NAACL.</p>
            <p><strong>Abstract:</strong> In the age of deep networks, "learning" almost invariably means "learning from examples". We train language models with human-generated text and labeled preference pairs, mage classifiers with large datasets of images, and robot policies with rollouts or demonstrations. When human learners acquire new concepts and skills, we often do so with richer supervision, especially in the form of language---we learn new concepts from examples accompanied by descriptions or definitions, and new skills from demonstrations accompanied by instructions. Current language models (LMs) support a limited form of language-based teaching via prompting, but it remains challenging to use natural language supervision to apply global, persistent changes to learned models. This talk will focus on two recent projects aimed at more effectively supervising LMs using language: first, on *eliciting* new information (by asking questions to human users of LMs); second, on *updating* language models to incorporate new information (by using LMs to automatically ask and answer questions about information implied by, but not explicitly stated in, training data). If time permits, I'll also discuss some applications of these techniques to educational settings (where we can optimize questions for human, rather than machine, learning). This is joint work with Belinda Li, Alex Tamkin, Noah Goodman, Feyza Akyürek, Ekin Akyürek, Leshem Choshen, Derry Wijaya, and Alexis Ross. </p>
        </div>
    </div>

<!-- Brihi Block -->
    <div class="talk"  onclick="toggleDetails(this)">
        <div class="talk-summary">
            <div class="date">
                <div class="month">OCT</div>
                <div class="day">3</div>
            </div>
            <div class="speaker-image">
                <a href="https://brihijoshi.github.io/" target="_block">
                <img src="https://brihijoshi.github.io/assets/img/brihi5.png" alt="Brihi Joshi" style="max-height: 300px;"/>
                </a>
            </div>
            <div class="speaker-text">
                <h3>Towards Richer User Signals for Personalization</h3>
                <p><img src="icons/person.png" alt="Person Icon" class="icon"><a href="https://brihijoshi.github.io/">Brihi Joshi</a></p>
                <p><img src="icons/clock.png" alt="Clock Icon" class="icon">October 3, 2025, 2:00 PM</p>
                <p><img src="icons/location.png" alt="Location Icon" class="icon">289, Engineering VI</p>
                <!-- <p><img src="icons/zoom.png" alt="Zoom Icon" class="icon">To Be Announced</p> -->
            </div>
            <div class="footer">
                <button class="more-details">More Details</button>
              </div>
        </div>
        <div class="talk-details">
            <p><strong>Speaker Bio:</strong> Brihi Joshi is a final-year PhD student in Computer Science at the University of Southern California, advised by Xiang Ren and Swabha Swayamdipta. Her research focuses on human-AI interaction, with an emphasis on personalization, where she designs and evaluates interactive systems that adapt to users in meaningful and useful ways. Her work has been supported by fellowships from Apple and Amazon. </p>
            <p><strong>Abstract:</strong> Personalization is gaining attention across domains, with different works exploring signals ranging from user demographics to interaction history. The talk will begin by showing that common signals such as prompts and instructions are underspecified for truly useful personalization, leading only to surface-level changes; for example, failing to adapt to learners with different educational backgrounds. We will then present how LLMs can be used to synthesize richer signals, such as user explanations, that drive more meaningful personalization. Finally, we will share ongoing work on training systems to actively elicit useful user signals, and touch upon open problems on how we can obtain and use these user signals. </p>
        </div>
    </div>




            

        
    
        








<!--     <div class="talk"  onclick="toggleDetails(this)">
        <div class="talk-summary">
            <div class="date">
                <div class="month">JAN</div>
                <div class="day">10</div>
            </div>
            <div class="speaker-image">
                <a href="https://swabhs.com/" target="_block">
                <img src="Image Link" alt="Speaker Name" style="max-height: 300px;"/>
                </a>
            </div>
            <div class="speaker-text">
                <h3>Talk Title</h3>
                <p><img src="icons/person.png" alt="Person Icon" class="icon"><a href="Speaker Website">Speaker Name</a></p>
                <p><img src="icons/clock.png" alt="Clock Icon" class="icon">Jan 10, 2024, 2:00 PM</p>
                <p><img src="icons/location.png" alt="Location Icon" class="icon">289, Engineering VI</p>
                <p><img src="icons/zoom.png" alt="Zoom Icon" class="icon">To Be Announced</p>
            </div>
            <div class="footer">
                <button class="more-details">More Details</button>
              </div>
        </div>
        <div class="talk-details">
            <p><strong>Speaker Bio:</strong> INSERT BIO </p>
            <p><strong>Abstract:</strong> INSERT TALK ABSTRACT HERE </p>
        </div>
    </div> -->

    
    <h2>Organizing Committee</h2>
    <div class="committee-content">
        <h3>Faculty</h3>
        <div class="row">
                <div class="speaker-image">
                        <a href="https://web.cs.ucla.edu/~kwchang/" target="_block">
                            <img src="https://web.cs.ucla.edu/~kwchang/img/myphoto.jpg" style="max-height: 200px; max-width: 200px;"/>
                        </a>
                    </figure>
                    <p><b>Prof. Kai-Wei Chang</b></p>
                </div>

                <div class="speaker-image">
                    <a href="https://violetpeng.github.io/" target="_block">
                        <img src="https://violetpeng.github.io/photos/profile22.png" style="max-height: 200px; max-width: 200px;"/>
                    </a>
                </figure>
                <p><b>Prof. Nanyun Peng </b></p>
                </div>

                <div class="speaker-image">
                    <a href="https://saadiagabriel.com/" target="_block">
                        <img src="https://saadiagabriel.com/website.png" style="max-height: 200px; max-width: 200px;"/>
                    </a>
                </figure>
                <p><b>Prof. Saadia Gabriel </b></p>
                </div>

                <div class="speaker-image">
                    <a href="https://www.coalas-lab.com/elisakreiss" target="_block">
                        <img src="https://comm.ucla.edu/wp-content/uploads/2023/08/ElisaSept2022.png" style="max-height: 200px; max-width: 200px;"/>
                    </a>
                </figure>
                <p><b>Prof. Elisa Kreiss </b></p>
            </div>

            </div>

    
        <div style="clear: both; text-align: left;">
            <h3>Students</h3>
            </div>
        <div class="row">
                <div class="speaker-image">
                        <a href="https://tanmayparekh.github.io/" target="_block">
                            <img src="https://tanmayparekh.github.io/vertical-ucla-pic.jpeg" style="max-height: 200px; max-width: 200px;"/>
                        </a>
                    </figure>
                    <p><b>Tanmay Parekh</b></p>
                </div>

                <div class="speaker-image">
                    <a href="https://mohsenfayyaz.github.io/" target="_block">
                        <img src="https://mohsenfayyaz.github.io/images/profile.jpg" style="max-height: 200px; max-width: 200px;"/>
                    </a>
                </figure>
                <p><b>Mohsen Fayyaz</b></p>
            </div>

                <div class="speaker-image">
                    <a href="https://asuvarna31.github.io" target="_block">
                        <img src="https://asuvarna31.github.io/images/IMG_0888.jpg" style="max-height: 200px; max-width: 200px;"/>
                    </a>
                </figure>
                <p><b>Ashima Suvarna</b></p>
                </div>
                </div>

                <div class="speaker-image">
                    <a href="https://www.lucasbandarkar.com/" target="_block">
                        <img src="https://lh3.googleusercontent.com/sitesv/AICyYdaPf5CwexYmJe7mCtc0rRFC5EVsCFSsj3BixcbWrDehTvCUHdKHPqs-wRVX-SSE6HWpvVYNQImTs3mgcJzz3KZYrM5Yy1TP_7vBSB3uzH1Ue8cFr4VopUE0cRo47fdHIKczVWJSbauIMPnFXdligp_mUfHjtLUMET4qbyOmgh3bWEWQ86SulqI55B4ul_YAI1SKAo3M9CRRkwaty-axfbhFURhuCmiDGrNu=w1280" style="max-height: 200px; max-width: 200px;"/>
                    </a>
                </figure>
                <p><b>Lucas Bandarkar</b></p>
                </div>

                <div class="row">
                

                <div class="speaker-image">
                    <a href="https://yingjia.one/" target="_block">
                        <img src="https://yingjia.one/authors/admin/avatar_hu3c4cd2cebe0e078637013a2cb9d92dd2_828858_270x270_fill_q75_lanczos_center.jpg" style="max-height: 200px;"/>
                    </a>
                </figure>
                <p><b>Yingjia Wan</b></p>
                </div>

                   <div class="speaker-image">
                    <a href="https://salmanrahman.net/" target="_block">
                        <img src="https://salmanrahman.net/assets/salman-img.jpg" style="max-height: 200px;"/>
                    </a>
                </figure>
                <p><b>Salman Rahman </b></p>
                </div>

            </div>


    </div>

    </main>

</body>

</html>
